{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f95b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Imports\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e20c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 14640\n",
      "Sentiment distribution:\n",
      "airline_sentiment\n",
      "negative    9178\n",
      "neutral     3099\n",
      "positive    2363\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — Load Dataset\n",
    "ds = load_dataset(\"7Xan7der7/us_airline_sentiment\")\n",
    "df = pd.DataFrame(ds[\"train\"])\n",
    "\n",
    "print(f\"Rows: {len(df)}\")\n",
    "print(f\"Sentiment distribution:\\n{df['airline_sentiment'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "937b443c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample:\n",
      "                                                text  \\\n",
      "0                @VirginAmerica What @dhepburn said.   \n",
      "1  @VirginAmerica plus you've added commercials t...   \n",
      "2  @VirginAmerica I didn't today... Must mean I n...   \n",
      "\n",
      "                                          text_clean  label  \n",
      "0                                         What said.      1  \n",
      "1  plus you've added commercials to the experienc...      2  \n",
      "2  I didn't today... Must mean I need to take ano...      1  \n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — Minimal Preprocessing (for embeddings)\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)          # Remove @mentions\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text) # Remove URLs\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()   # Clean whitespace\n",
    "    return text\n",
    "\n",
    "df[\"text_clean\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "# Encode labels: negative=0, neutral=1, positive=2\n",
    "label_map = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "df[\"label\"] = df[\"airline_sentiment\"].map(label_map)\n",
    "\n",
    "print(\"Sample:\")\n",
    "print(df[[\"text\", \"text_clean\", \"label\"]].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dcc2bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 11712 | Test: 2928\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text_clean\"], df[\"label\"],\n",
    "    test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "# Reset indices for consistency\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f1a6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating train embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c576d087bab348fbae6f93b3a560ff74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa04dedaff84590ba85876679789926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (11712, 384) (384 dims)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 — Generate Embeddings\n",
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "embedder = SentenceTransformer(model_name)\n",
    "\n",
    "print(\"Generating train embeddings...\")\n",
    "train_embeddings = embedder.encode(X_train.tolist(), show_progress_bar=True)\n",
    "\n",
    "print(\"Generating test embeddings...\")\n",
    "test_embeddings = embedder.encode(X_test.tolist(), show_progress_bar=True)\n",
    "\n",
    "print(f\"Shape: {train_embeddings.shape} (384 dims)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbd8337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding train embeddings...\n",
      "  Added batch 0-5000\n",
      "  Added batch 5000-10000\n",
      "  Added batch 10000-11712\n",
      "Adding test embeddings...\n",
      "  Added batch 0-2928\n",
      "\n",
      "Stored: Train=11712 | Test=2928\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 — Store in ChromaDB\n",
    "import os\n",
    "chroma_path = os.path.abspath(\"../chromadb_data\")\n",
    "chroma_client = chromadb.PersistentClient(path=chroma_path)\n",
    "\n",
    "# Clean start\n",
    "for name in [\"train_embeddings\", \"test_embeddings\"]:\n",
    "    try:\n",
    "        chroma_client.delete_collection(name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Create collections\n",
    "train_col = chroma_client.create_collection(\"train_embeddings\")\n",
    "test_col = chroma_client.create_collection(\"test_embeddings\")\n",
    "\n",
    "# Add in batches (ChromaDB max is 5461)\n",
    "batch_size = 5000\n",
    "\n",
    "def add_in_batches(collection, embeddings, labels):\n",
    "    for i in range(0, len(embeddings), batch_size):\n",
    "        end = min(i + batch_size, len(embeddings))\n",
    "        collection.add(\n",
    "            ids=[str(j) for j in range(i, end)],\n",
    "            embeddings=embeddings[i:end].tolist(),\n",
    "            metadatas=[{\"label\": int(y)} for y in labels[i:end]]\n",
    "        )\n",
    "        print(f\"  Added batch {i}-{end}\")\n",
    "\n",
    "print(\"Adding train embeddings...\")\n",
    "add_in_batches(train_col, train_embeddings, y_train)\n",
    "\n",
    "print(\"Adding test embeddings...\")\n",
    "add_in_batches(test_col, test_embeddings, y_test)\n",
    "\n",
    "print(f\"\\nStored: Train={train_col.count()} | Test={test_col.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd6f195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8479\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 — Retrieve & Train Logistic Regression\n",
    "train_data = train_col.get(include=[\"embeddings\", \"metadatas\"])\n",
    "test_data = test_col.get(include=[\"embeddings\", \"metadatas\"])\n",
    "\n",
    "X_train_emb = np.array(train_data[\"embeddings\"])\n",
    "y_train_emb = np.array([m[\"label\"] for m in train_data[\"metadatas\"]])\n",
    "\n",
    "X_test_emb = np.array(test_data[\"embeddings\"])\n",
    "y_test_emb = np.array([m[\"label\"] for m in test_data[\"metadatas\"]])\n",
    "\n",
    "# Train\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_emb, y_train_emb)\n",
    "\n",
    "print(f\"Train accuracy: {clf.score(X_train_emb, y_train_emb):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10886b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8231\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.90      1835\n",
      "     neutral       0.68      0.65      0.67       620\n",
      "    positive       0.77      0.70      0.73       473\n",
      "\n",
      "    accuracy                           0.82      2928\n",
      "   macro avg       0.78      0.76      0.77      2928\n",
      "weighted avg       0.82      0.82      0.82      2928\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1673  114   48]\n",
      " [ 163  406   51]\n",
      " [  63   79  331]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 — Evaluate\n",
    "y_pred = clf.predict(X_test_emb)\n",
    "\n",
    "print(f\"Test accuracy: {clf.score(X_test_emb, y_test_emb):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_emb, y_pred, target_names=[\"negative\", \"neutral\", \"positive\"]))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_emb, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f68e228b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/logreg_embedding.joblib\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 — Save Model\n",
    "import os\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(clf, \"../models/logreg_embedding.joblib\")\n",
    "print(\"Model saved to ../models/logreg_embedding.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "717adfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "negative\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "# Cell 10 — Quick Inference Test\n",
    "def predict_sentiment(text):\n",
    "    text_clean = clean_text(text)\n",
    "    embedding = embedder.encode([text_clean])\n",
    "    pred = clf.predict(embedding)[0]\n",
    "    labels = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "    return labels[pred]\n",
    "\n",
    "# Test\n",
    "print(predict_sentiment(\"The flight was amazing!\"))\n",
    "print(predict_sentiment(\"Terrible service, never again.\"))\n",
    "print(predict_sentiment(\"It was okay, nothing special.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
